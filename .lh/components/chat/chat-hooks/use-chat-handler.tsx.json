{
    "sourceFile": "components/chat/chat-hooks/use-chat-handler.tsx",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1718041880006,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1718041887765,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,342 +1,342 @@\n-const handleNewChat = async () => {\n-  if (!selectedWorkspace) return\n+  const handleNewChat = async () => {\n+    if (!selectedWorkspace) return\n \n-  setUserInput(\"\")\n-  setChatMessages([])\n-  setSelectedChat(null)\n-  setChatFileItems([])\n+    setUserInput(\"\")\n+    setChatMessages([])\n+    setSelectedChat(null)\n+    setChatFileItems([])\n \n-  setIsGenerating(false)\n-  setFirstTokenReceived(false)\n+    setIsGenerating(false)\n+    setFirstTokenReceived(false)\n \n-  setChatFiles([])\n-  setChatImages([])\n-  setNewMessageFiles([])\n-  setNewMessageImages([])\n-  setShowFilesDisplay(false)\n-  setIsPromptPickerOpen(false)\n-  setIsFilePickerOpen(false)\n+    setChatFiles([])\n+    setChatImages([])\n+    setNewMessageFiles([])\n+    setNewMessageImages([])\n+    setShowFilesDisplay(false)\n+    setIsPromptPickerOpen(false)\n+    setIsFilePickerOpen(false)\n \n-  setSelectedTools([])\n-  setToolInUse(\"none\")\n+    setSelectedTools([])\n+    setToolInUse(\"none\")\n \n-  if (selectedAssistant) {\n-    setChatSettings({\n-      model: selectedAssistant.model as LLMID,\n-      prompt: selectedAssistant.prompt,\n-      temperature: selectedAssistant.temperature,\n-      contextLength: selectedAssistant.context_length,\n-      includeProfileContext: selectedAssistant.include_profile_context,\n-      includeWorkspaceInstructions:\n-        selectedAssistant.include_workspace_instructions,\n-      embeddingsProvider: selectedAssistant.embeddings_provider as\n-        | \"openai\"\n-        | \"local\"\n-    })\n+    if (selectedAssistant) {\n+      setChatSettings({\n+        model: selectedAssistant.model as LLMID,\n+        prompt: selectedAssistant.prompt,\n+        temperature: selectedAssistant.temperature,\n+        contextLength: selectedAssistant.context_length,\n+        includeProfileContext: selectedAssistant.include_profile_context,\n+        includeWorkspaceInstructions:\n+          selectedAssistant.include_workspace_instructions,\n+        embeddingsProvider: selectedAssistant.embeddings_provider as\n+          | \"openai\"\n+          | \"local\"\n+      })\n \n-    let allFiles = []\n+      let allFiles = []\n \n-    const assistantFiles = (\n-      await getAssistantFilesByAssistantId(selectedAssistant.id)\n-    ).files\n-    allFiles = [...assistantFiles]\n-    const assistantCollections = (\n-      await getAssistantCollectionsByAssistantId(selectedAssistant.id)\n-    ).collections\n-    for (const collection of assistantCollections) {\n-      const collectionFiles = (\n-        await getCollectionFilesByCollectionId(collection.id)\n+      const assistantFiles = (\n+        await getAssistantFilesByAssistantId(selectedAssistant.id)\n       ).files\n-      allFiles = [...allFiles, ...collectionFiles]\n+      allFiles = [...assistantFiles]\n+      const assistantCollections = (\n+        await getAssistantCollectionsByAssistantId(selectedAssistant.id)\n+      ).collections\n+      for (const collection of assistantCollections) {\n+        const collectionFiles = (\n+          await getCollectionFilesByCollectionId(collection.id)\n+        ).files\n+        allFiles = [...allFiles, ...collectionFiles]\n+      }\n+      const assistantTools = (\n+        await getAssistantToolsByAssistantId(selectedAssistant.id)\n+      ).tools\n+\n+      setSelectedTools(assistantTools)\n+      setChatFiles(\n+        allFiles.map(file => ({\n+          id: file.id,\n+          name: file.name,\n+          type: file.type,\n+          file: null\n+        }))\n+      )\n+\n+      if (allFiles.length > 0) setShowFilesDisplay(true)\n+    } else if (selectedPreset) {\n+      setChatSettings({\n+        model: selectedPreset.model as LLMID,\n+        prompt: selectedPreset.prompt,\n+        temperature: selectedPreset.temperature,\n+        contextLength: selectedPreset.context_length,\n+        includeProfileContext: selectedPreset.include_profile_context,\n+        includeWorkspaceInstructions:\n+          selectedPreset.include_workspace_instructions,\n+        embeddingsProvider: selectedPreset.embeddings_provider as\n+          | \"openai\"\n+          | \"local\"\n+      })\n+    } else if (selectedWorkspace) {\n+      // setChatSettings({\n+      //   model: (selectedWorkspace.default_model ||\n+      //     \"gpt-4-1106-preview\") as LLMID,\n+      //   prompt:\n+      //     selectedWorkspace.default_prompt ||\n+      //     \"You are a friendly, helpful AI assistant.\",\n+      //   temperature: selectedWorkspace.default_temperature || 0.5,\n+      //   contextLength: selectedWorkspace.default_context_length || 4096,\n+      //   includeProfileContext:\n+      //     selectedWorkspace.include_profile_context || true,\n+      //   includeWorkspaceInstructions:\n+      //     selectedWorkspace.include_workspace_instructions || true,\n+      //   embeddingsProvider:\n+      //     (selectedWorkspace.embeddings_provider as \"openai\" | \"local\") ||\n+      //     \"openai\"\n+      // })\n     }\n-    const assistantTools = (\n-      await getAssistantToolsByAssistantId(selectedAssistant.id)\n-    ).tools\n \n-    setSelectedTools(assistantTools)\n-    setChatFiles(\n-      allFiles.map(file => ({\n-        id: file.id,\n-        name: file.name,\n-        type: file.type,\n-        file: null\n-      }))\n-    )\n+    return router.push(`/${selectedWorkspace.id}/chat`)\n+  }\n \n-    if (allFiles.length > 0) setShowFilesDisplay(true)\n-  } else if (selectedPreset) {\n-    setChatSettings({\n-      model: selectedPreset.model as LLMID,\n-      prompt: selectedPreset.prompt,\n-      temperature: selectedPreset.temperature,\n-      contextLength: selectedPreset.context_length,\n-      includeProfileContext: selectedPreset.include_profile_context,\n-      includeWorkspaceInstructions:\n-        selectedPreset.include_workspace_instructions,\n-      embeddingsProvider: selectedPreset.embeddings_provider as\n-        | \"openai\"\n-        | \"local\"\n-    })\n-  } else if (selectedWorkspace) {\n-    // setChatSettings({\n-    //   model: (selectedWorkspace.default_model ||\n-    //     \"gpt-4-1106-preview\") as LLMID,\n-    //   prompt:\n-    //     selectedWorkspace.default_prompt ||\n-    //     \"You are a friendly, helpful AI assistant.\",\n-    //   temperature: selectedWorkspace.default_temperature || 0.5,\n-    //   contextLength: selectedWorkspace.default_context_length || 4096,\n-    //   includeProfileContext:\n-    //     selectedWorkspace.include_profile_context || true,\n-    //   includeWorkspaceInstructions:\n-    //     selectedWorkspace.include_workspace_instructions || true,\n-    //   embeddingsProvider:\n-    //     (selectedWorkspace.embeddings_provider as \"openai\" | \"local\") ||\n-    //     \"openai\"\n-    // })\n+  const handleFocusChatInput = () => {\n+    chatInputRef.current?.focus()\n   }\n \n-  return router.push(`/${selectedWorkspace.id}/chat`)\n-}\n-\n-const handleFocusChatInput = () => {\n-  chatInputRef.current?.focus()\n-}\n-\n-const handleStopMessage = () => {\n-  if (abortController) {\n-    abortController.abort()\n+  const handleStopMessage = () => {\n+    if (abortController) {\n+      abortController.abort()\n+    }\n   }\n-}\n \n-const handleSendMessage = async (\n-  messageContent: string,\n-  chatMessages: ChatMessage[],\n-  isRegeneration: boolean\n-) => {\n-  const startingInput = messageContent\n+  const handleSendMessage = async (\n+    messageContent: string,\n+    chatMessages: ChatMessage[],\n+    isRegeneration: boolean\n+  ) => {\n+    const startingInput = messageContent\n \n-  try {\n-    setUserInput(\"\")\n-    setIsGenerating(true)\n-    setIsPromptPickerOpen(false)\n-    setIsFilePickerOpen(false)\n-    setNewMessageImages([])\n+    try {\n+      setUserInput(\"\")\n+      setIsGenerating(true)\n+      setIsPromptPickerOpen(false)\n+      setIsFilePickerOpen(false)\n+      setNewMessageImages([])\n \n-    const newAbortController = new AbortController()\n-    setAbortController(newAbortController)\n+      const newAbortController = new AbortController()\n+      setAbortController(newAbortController)\n \n-    const modelData = [\n-      ...models.map(model => ({\n-        modelId: model.model_id as LLMID,\n-        modelName: model.name,\n-        provider: \"custom\" as ModelProvider,\n-        hostedId: model.id,\n-        platformLink: \"\",\n-        imageInput: false\n-      })),\n-      ...LLM_LIST,\n-      ...availableLocalModels,\n-      ...availableOpenRouterModels\n-    ].find(llm => llm.modelId === chatSettings?.model)\n+      const modelData = [\n+        ...models.map(model => ({\n+          modelId: model.model_id as LLMID,\n+          modelName: model.name,\n+          provider: \"custom\" as ModelProvider,\n+          hostedId: model.id,\n+          platformLink: \"\",\n+          imageInput: false\n+        })),\n+        ...LLM_LIST,\n+        ...availableLocalModels,\n+        ...availableOpenRouterModels\n+      ].find(llm => llm.modelId === chatSettings?.model)\n \n-    validateChatSettings(\n-      chatSettings,\n-      modelData,\n-      profile,\n-      selectedWorkspace,\n-      messageContent\n-    )\n+      validateChatSettings(\n+        chatSettings,\n+        modelData,\n+        profile,\n+        selectedWorkspace,\n+        messageContent\n+      )\n \n-    let currentChat = selectedChat ? { ...selectedChat } : null\n+      let currentChat = selectedChat ? { ...selectedChat } : null\n \n-    const b64Images = newMessageImages.map(image => image.base64)\n+      const b64Images = newMessageImages.map(image => image.base64)\n \n-    let retrievedFileItems: Tables<\"file_items\">[] = []\n+      let retrievedFileItems: Tables<\"file_items\">[] = []\n \n-    if (\n-      (newMessageFiles.length > 0 || chatFiles.length > 0) &&\n-      useRetrieval\n-    ) {\n-      setToolInUse(\"retrieval\")\n+      if (\n+        (newMessageFiles.length > 0 || chatFiles.length > 0) &&\n+        useRetrieval\n+      ) {\n+        setToolInUse(\"retrieval\")\n \n-      retrievedFileItems = await handleRetrieval(\n-        userInput,\n-        newMessageFiles,\n-        chatFiles,\n-        chatSettings!.embeddingsProvider,\n-        sourceCount\n-      )\n-    }\n+        retrievedFileItems = await handleRetrieval(\n+          userInput,\n+          newMessageFiles,\n+          chatFiles,\n+          chatSettings!.embeddingsProvider,\n+          sourceCount\n+        )\n+      }\n \n-    const { tempUserChatMessage, tempAssistantChatMessage } =\n-      createTempMessages(\n-        messageContent,\n-        chatMessages,\n-        chatSettings!,\n-        b64Images,\n-        isRegeneration,\n-        setChatMessages,\n-        selectedAssistant\n-      )\n+      const { tempUserChatMessage, tempAssistantChatMessage } =\n+        createTempMessages(\n+          messageContent,\n+          chatMessages,\n+          chatSettings!,\n+          b64Images,\n+          isRegeneration,\n+          setChatMessages,\n+          selectedAssistant\n+        )\n \n-    let payload: ChatPayload = {\n-      chatSettings: chatSettings!,\n-      workspaceInstructions: selectedWorkspace!.instructions || \"\",\n-      chatMessages: isRegeneration\n-        ? [...chatMessages]\n-        : [...chatMessages, tempUserChatMessage],\n-      assistant: selectedChat?.assistant_id ? selectedAssistant : null,\n-      messageFileItems: retrievedFileItems,\n-      chatFileItems: chatFileItems\n-    }\n+      let payload: ChatPayload = {\n+        chatSettings: chatSettings!,\n+        workspaceInstructions: selectedWorkspace!.instructions || \"\",\n+        chatMessages: isRegeneration\n+          ? [...chatMessages]\n+          : [...chatMessages, tempUserChatMessage],\n+        assistant: selectedChat?.assistant_id ? selectedAssistant : null,\n+        messageFileItems: retrievedFileItems,\n+        chatFileItems: chatFileItems\n+      }\n \n-    let generatedText = \"\"\n+      let generatedText = \"\"\n \n-    if (selectedTools.length > 0) {\n-      setToolInUse(\"Tools\")\n+      if (selectedTools.length > 0) {\n+        setToolInUse(\"Tools\")\n \n-      const formattedMessages = await buildFinalMessages(\n-        payload,\n-        profile!,\n-        chatImages\n-      )\n+        const formattedMessages = await buildFinalMessages(\n+          payload,\n+          profile!,\n+          chatImages\n+        )\n \n-      const response = await fetch(\"/api/chat/tools\", {\n-        method: \"POST\",\n-        headers: {\n-          \"Content-Type\": \"application/json\"\n-        },\n-        body: JSON.stringify({\n-          chatSettings: payload.chatSettings,\n-          messages: formattedMessages,\n-          selectedTools\n+        const response = await fetch(\"/api/chat/tools\", {\n+          method: \"POST\",\n+          headers: {\n+            \"Content-Type\": \"application/json\"\n+          },\n+          body: JSON.stringify({\n+            chatSettings: payload.chatSettings,\n+            messages: formattedMessages,\n+            selectedTools\n+          })\n         })\n-      })\n \n-      setToolInUse(\"none\")\n+        setToolInUse(\"none\")\n \n-      generatedText = await processResponse(\n-        response,\n-        isRegeneration\n-          ? payload.chatMessages[payload.chatMessages.length - 1]\n-          : tempAssistantChatMessage,\n-        true,\n-        newAbortController,\n-        setFirstTokenReceived,\n-        setChatMessages,\n-        setToolInUse\n-      )\n-    } else {\n-      if (modelData!.provider === \"ollama\") {\n-        generatedText = await handleLocalChat(\n-          payload,\n-          profile!,\n-          chatSettings!,\n-          tempAssistantChatMessage,\n-          isRegeneration,\n+        generatedText = await processResponse(\n+          response,\n+          isRegeneration\n+            ? payload.chatMessages[payload.chatMessages.length - 1]\n+            : tempAssistantChatMessage,\n+          true,\n           newAbortController,\n-          setIsGenerating,\n           setFirstTokenReceived,\n           setChatMessages,\n           setToolInUse\n         )\n       } else {\n-        generatedText = await handleHostedChat(\n-          payload,\n+        if (modelData!.provider === \"ollama\") {\n+          generatedText = await handleLocalChat(\n+            payload,\n+            profile!,\n+            chatSettings!,\n+            tempAssistantChatMessage,\n+            isRegeneration,\n+            newAbortController,\n+            setIsGenerating,\n+            setFirstTokenReceived,\n+            setChatMessages,\n+            setToolInUse\n+          )\n+        } else {\n+          generatedText = await handleHostedChat(\n+            payload,\n+            profile!,\n+            modelData!,\n+            tempAssistantChatMessage,\n+            isRegeneration,\n+            newAbortController,\n+            newMessageImages,\n+            chatImages,\n+            setIsGenerating,\n+            setFirstTokenReceived,\n+            setChatMessages,\n+            setToolInUse\n+          )\n+        }\n+      }\n+\n+      if (!currentChat) {\n+        currentChat = await handleCreateChat(\n+          chatSettings!,\n           profile!,\n-          modelData!,\n-          tempAssistantChatMessage,\n-          isRegeneration,\n-          newAbortController,\n-          newMessageImages,\n-          chatImages,\n-          setIsGenerating,\n-          setFirstTokenReceived,\n-          setChatMessages,\n-          setToolInUse\n+          selectedWorkspace!,\n+          messageContent,\n+          selectedAssistant!,\n+          newMessageFiles,\n+          setSelectedChat,\n+          setChats,\n+          setChatFiles\n         )\n+      } else {\n+        const updatedChat = await updateChat(currentChat.id, {\n+          updated_at: new Date().toISOString()\n+        })\n+\n+        setChats(prevChats => {\n+          const updatedChats = prevChats.map(prevChat =>\n+            prevChat.id === updatedChat.id ? updatedChat : prevChat\n+          )\n+\n+          return updatedChats\n+        })\n       }\n-    }\n \n-    if (!currentChat) {\n-      currentChat = await handleCreateChat(\n-        chatSettings!,\n+      await handleCreateMessages(\n+        chatMessages,\n+        currentChat,\n         profile!,\n-        selectedWorkspace!,\n+        modelData!,\n         messageContent,\n-        selectedAssistant!,\n-        newMessageFiles,\n-        setSelectedChat,\n-        setChats,\n-        setChatFiles\n+        generatedText,\n+        newMessageImages,\n+        isRegeneration,\n+        retrievedFileItems,\n+        setChatMessages,\n+        setChatFileItems,\n+        setChatImages,\n+        selectedAssistant\n       )\n-    } else {\n-      const updatedChat = await updateChat(currentChat.id, {\n-        updated_at: new Date().toISOString()\n-      })\n \n-      setChats(prevChats => {\n-        const updatedChats = prevChats.map(prevChat =>\n-          prevChat.id === updatedChat.id ? updatedChat : prevChat\n-        )\n-\n-        return updatedChats\n-      })\n+      setIsGenerating(false)\n+      setFirstTokenReceived(false)\n+    } catch (error) {\n+      setIsGenerating(false)\n+      setFirstTokenReceived(false)\n+      setUserInput(startingInput)\n     }\n-\n-    await handleCreateMessages(\n-      chatMessages,\n-      currentChat,\n-      profile!,\n-      modelData!,\n-      messageContent,\n-      generatedText,\n-      newMessageImages,\n-      isRegeneration,\n-      retrievedFileItems,\n-      setChatMessages,\n-      setChatFileItems,\n-      setChatImages,\n-      selectedAssistant\n-    )\n-\n-    setIsGenerating(false)\n-    setFirstTokenReceived(false)\n-  } catch (error) {\n-    setIsGenerating(false)\n-    setFirstTokenReceived(false)\n-    setUserInput(startingInput)\n   }\n-}\n \n-const handleSendEdit = async (\n-  editedContent: string,\n-  sequenceNumber: number\n-) => {\n-  if (!selectedChat) return\n+  const handleSendEdit = async (\n+    editedContent: string,\n+    sequenceNumber: number\n+  ) => {\n+    if (!selectedChat) return\n \n-  await deleteMessagesIncludingAndAfter(\n-    selectedChat.user_id,\n-    selectedChat.id,\n-    sequenceNumber\n-  )\n+    await deleteMessagesIncludingAndAfter(\n+      selectedChat.user_id,\n+      selectedChat.id,\n+      sequenceNumber\n+    )\n \n-  const filteredMessages = chatMessages.filter(\n-    chatMessage => chatMessage.message.sequence_number < sequenceNumber\n-  )\n+    const filteredMessages = chatMessages.filter(\n+      chatMessage => chatMessage.message.sequence_number < sequenceNumber\n+    )\n \n-  setChatMessages(filteredMessages)\n+    setChatMessages(filteredMessages)\n \n-  handleSendMessage(editedContent, filteredMessages, false)\n-}\n+    handleSendMessage(editedContent, filteredMessages, false)\n+  }\n \n-return {\n-  chatInputRef,\n-  handleNewChat,\n-  handleSendMessage,\n-  handleFocusChatInput,\n-  handleStopMessage,\n-  handleSendEdit\n+  return {\n+    chatInputRef,\n+    handleNewChat,\n+    handleSendMessage,\n+    handleFocusChatInput,\n+    handleStopMessage,\n+    handleSendEdit\n+  }\n }\n-}\n"
                },
                {
                    "date": 1718041893688,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,4 +1,85 @@\n+import { ChatbotUIContext } from \"@/context/context\"\n+import { getAssistantCollectionsByAssistantId } from \"@/db/assistant-collections\"\n+import { getAssistantFilesByAssistantId } from \"@/db/assistant-files\"\n+import { getAssistantToolsByAssistantId } from \"@/db/assistant-tools\"\n+import { updateChat } from \"@/db/chats\"\n+import { getCollectionFilesByCollectionId } from \"@/db/collection-files\"\n+import { deleteMessagesIncludingAndAfter } from \"@/db/messages\"\n+import { buildFinalMessages } from \"@/lib/build-prompt\"\n+import { Tables } from \"@/supabase/types\"\n+import { ChatMessage, ChatPayload, LLMID, ModelProvider } from \"@/types\"\n+import { useRouter } from \"next/navigation\"\n+import { useContext, useEffect, useRef } from \"react\"\n+import { LLM_LIST } from \"../../../lib/models/llm/llm-list\"\n+import {\n+  createTempMessages,\n+  handleCreateChat,\n+  handleCreateMessages,\n+  handleHostedChat,\n+  handleLocalChat,\n+  handleRetrieval,\n+  processResponse,\n+  validateChatSettings\n+} from \"../chat-helpers\"\n+// If `ChatGPTAssistant` needs to be imported\n+// import { ChatGPTAssistant } from \"@/components/chat-gpt-assistant\"\n+\n+export const useChatHandler = () => {\n+  const router = useRouter()\n+\n+  const {\n+    userInput,\n+    chatFiles,\n+    setUserInput,\n+    setNewMessageImages,\n+    profile,\n+    setIsGenerating,\n+    setChatMessages,\n+    setFirstTokenReceived,\n+    selectedChat,\n+    selectedWorkspace,\n+    setSelectedChat,\n+    setChats,\n+    setSelectedTools,\n+    availableLocalModels,\n+    availableOpenRouterModels,\n+    abortController,\n+    setAbortController,\n+    chatSettings,\n+    newMessageImages,\n+    selectedAssistant,\n+    chatMessages,\n+    chatImages,\n+    setChatImages,\n+    setChatFiles,\n+    setNewMessageFiles,\n+    setShowFilesDisplay,\n+    newMessageFiles,\n+    chatFileItems,\n+    setChatFileItems,\n+    setToolInUse,\n+    useRetrieval,\n+    sourceCount,\n+    setIsPromptPickerOpen,\n+    setIsFilePickerOpen,\n+    selectedTools,\n+    selectedPreset,\n+    setChatSettings,\n+    models,\n+    isPromptPickerOpen,\n+    isFilePickerOpen,\n+    isToolPickerOpen\n+  } = useContext(ChatbotUIContext)\n+\n+  const chatInputRef = useRef<HTMLTextAreaElement>(null)\n+\n+  useEffect(() => {\n+    if (!isPromptPickerOpen || !isFilePickerOpen || !isToolPickerOpen) {\n+      chatInputRef.current?.focus()\n+    }\n+  }, [isPromptPickerOpen, isFilePickerOpen, isToolPickerOpen])\n+\n   const handleNewChat = async () => {\n     if (!selectedWorkspace) return\n \n     setUserInput(\"\")\n@@ -332,8 +413,9 @@\n   }\n \n   return {\n     chatInputRef,\n+    prompt,\n     handleNewChat,\n     handleSendMessage,\n     handleFocusChatInput,\n     handleStopMessage,\n"
                },
                {
                    "date": 1718041977676,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -413,9 +413,8 @@\n   }\n \n   return {\n     chatInputRef,\n-    prompt,\n     handleNewChat,\n     handleSendMessage,\n     handleFocusChatInput,\n     handleStopMessage,\n"
                },
                {
                    "date": 1718042071893,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,10 +20,8 @@\n   handleRetrieval,\n   processResponse,\n   validateChatSettings\n } from \"../chat-helpers\"\n-// If `ChatGPTAssistant` needs to be imported\n-// import { ChatGPTAssistant } from \"@/components/chat-gpt-assistant\"\n \n export const useChatHandler = () => {\n   const router = useRouter()\n \n"
                }
            ],
            "date": 1718041880006,
            "name": "Commit-0",
            "content": "const handleNewChat = async () => {\n  if (!selectedWorkspace) return\n\n  setUserInput(\"\")\n  setChatMessages([])\n  setSelectedChat(null)\n  setChatFileItems([])\n\n  setIsGenerating(false)\n  setFirstTokenReceived(false)\n\n  setChatFiles([])\n  setChatImages([])\n  setNewMessageFiles([])\n  setNewMessageImages([])\n  setShowFilesDisplay(false)\n  setIsPromptPickerOpen(false)\n  setIsFilePickerOpen(false)\n\n  setSelectedTools([])\n  setToolInUse(\"none\")\n\n  if (selectedAssistant) {\n    setChatSettings({\n      model: selectedAssistant.model as LLMID,\n      prompt: selectedAssistant.prompt,\n      temperature: selectedAssistant.temperature,\n      contextLength: selectedAssistant.context_length,\n      includeProfileContext: selectedAssistant.include_profile_context,\n      includeWorkspaceInstructions:\n        selectedAssistant.include_workspace_instructions,\n      embeddingsProvider: selectedAssistant.embeddings_provider as\n        | \"openai\"\n        | \"local\"\n    })\n\n    let allFiles = []\n\n    const assistantFiles = (\n      await getAssistantFilesByAssistantId(selectedAssistant.id)\n    ).files\n    allFiles = [...assistantFiles]\n    const assistantCollections = (\n      await getAssistantCollectionsByAssistantId(selectedAssistant.id)\n    ).collections\n    for (const collection of assistantCollections) {\n      const collectionFiles = (\n        await getCollectionFilesByCollectionId(collection.id)\n      ).files\n      allFiles = [...allFiles, ...collectionFiles]\n    }\n    const assistantTools = (\n      await getAssistantToolsByAssistantId(selectedAssistant.id)\n    ).tools\n\n    setSelectedTools(assistantTools)\n    setChatFiles(\n      allFiles.map(file => ({\n        id: file.id,\n        name: file.name,\n        type: file.type,\n        file: null\n      }))\n    )\n\n    if (allFiles.length > 0) setShowFilesDisplay(true)\n  } else if (selectedPreset) {\n    setChatSettings({\n      model: selectedPreset.model as LLMID,\n      prompt: selectedPreset.prompt,\n      temperature: selectedPreset.temperature,\n      contextLength: selectedPreset.context_length,\n      includeProfileContext: selectedPreset.include_profile_context,\n      includeWorkspaceInstructions:\n        selectedPreset.include_workspace_instructions,\n      embeddingsProvider: selectedPreset.embeddings_provider as\n        | \"openai\"\n        | \"local\"\n    })\n  } else if (selectedWorkspace) {\n    // setChatSettings({\n    //   model: (selectedWorkspace.default_model ||\n    //     \"gpt-4-1106-preview\") as LLMID,\n    //   prompt:\n    //     selectedWorkspace.default_prompt ||\n    //     \"You are a friendly, helpful AI assistant.\",\n    //   temperature: selectedWorkspace.default_temperature || 0.5,\n    //   contextLength: selectedWorkspace.default_context_length || 4096,\n    //   includeProfileContext:\n    //     selectedWorkspace.include_profile_context || true,\n    //   includeWorkspaceInstructions:\n    //     selectedWorkspace.include_workspace_instructions || true,\n    //   embeddingsProvider:\n    //     (selectedWorkspace.embeddings_provider as \"openai\" | \"local\") ||\n    //     \"openai\"\n    // })\n  }\n\n  return router.push(`/${selectedWorkspace.id}/chat`)\n}\n\nconst handleFocusChatInput = () => {\n  chatInputRef.current?.focus()\n}\n\nconst handleStopMessage = () => {\n  if (abortController) {\n    abortController.abort()\n  }\n}\n\nconst handleSendMessage = async (\n  messageContent: string,\n  chatMessages: ChatMessage[],\n  isRegeneration: boolean\n) => {\n  const startingInput = messageContent\n\n  try {\n    setUserInput(\"\")\n    setIsGenerating(true)\n    setIsPromptPickerOpen(false)\n    setIsFilePickerOpen(false)\n    setNewMessageImages([])\n\n    const newAbortController = new AbortController()\n    setAbortController(newAbortController)\n\n    const modelData = [\n      ...models.map(model => ({\n        modelId: model.model_id as LLMID,\n        modelName: model.name,\n        provider: \"custom\" as ModelProvider,\n        hostedId: model.id,\n        platformLink: \"\",\n        imageInput: false\n      })),\n      ...LLM_LIST,\n      ...availableLocalModels,\n      ...availableOpenRouterModels\n    ].find(llm => llm.modelId === chatSettings?.model)\n\n    validateChatSettings(\n      chatSettings,\n      modelData,\n      profile,\n      selectedWorkspace,\n      messageContent\n    )\n\n    let currentChat = selectedChat ? { ...selectedChat } : null\n\n    const b64Images = newMessageImages.map(image => image.base64)\n\n    let retrievedFileItems: Tables<\"file_items\">[] = []\n\n    if (\n      (newMessageFiles.length > 0 || chatFiles.length > 0) &&\n      useRetrieval\n    ) {\n      setToolInUse(\"retrieval\")\n\n      retrievedFileItems = await handleRetrieval(\n        userInput,\n        newMessageFiles,\n        chatFiles,\n        chatSettings!.embeddingsProvider,\n        sourceCount\n      )\n    }\n\n    const { tempUserChatMessage, tempAssistantChatMessage } =\n      createTempMessages(\n        messageContent,\n        chatMessages,\n        chatSettings!,\n        b64Images,\n        isRegeneration,\n        setChatMessages,\n        selectedAssistant\n      )\n\n    let payload: ChatPayload = {\n      chatSettings: chatSettings!,\n      workspaceInstructions: selectedWorkspace!.instructions || \"\",\n      chatMessages: isRegeneration\n        ? [...chatMessages]\n        : [...chatMessages, tempUserChatMessage],\n      assistant: selectedChat?.assistant_id ? selectedAssistant : null,\n      messageFileItems: retrievedFileItems,\n      chatFileItems: chatFileItems\n    }\n\n    let generatedText = \"\"\n\n    if (selectedTools.length > 0) {\n      setToolInUse(\"Tools\")\n\n      const formattedMessages = await buildFinalMessages(\n        payload,\n        profile!,\n        chatImages\n      )\n\n      const response = await fetch(\"/api/chat/tools\", {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify({\n          chatSettings: payload.chatSettings,\n          messages: formattedMessages,\n          selectedTools\n        })\n      })\n\n      setToolInUse(\"none\")\n\n      generatedText = await processResponse(\n        response,\n        isRegeneration\n          ? payload.chatMessages[payload.chatMessages.length - 1]\n          : tempAssistantChatMessage,\n        true,\n        newAbortController,\n        setFirstTokenReceived,\n        setChatMessages,\n        setToolInUse\n      )\n    } else {\n      if (modelData!.provider === \"ollama\") {\n        generatedText = await handleLocalChat(\n          payload,\n          profile!,\n          chatSettings!,\n          tempAssistantChatMessage,\n          isRegeneration,\n          newAbortController,\n          setIsGenerating,\n          setFirstTokenReceived,\n          setChatMessages,\n          setToolInUse\n        )\n      } else {\n        generatedText = await handleHostedChat(\n          payload,\n          profile!,\n          modelData!,\n          tempAssistantChatMessage,\n          isRegeneration,\n          newAbortController,\n          newMessageImages,\n          chatImages,\n          setIsGenerating,\n          setFirstTokenReceived,\n          setChatMessages,\n          setToolInUse\n        )\n      }\n    }\n\n    if (!currentChat) {\n      currentChat = await handleCreateChat(\n        chatSettings!,\n        profile!,\n        selectedWorkspace!,\n        messageContent,\n        selectedAssistant!,\n        newMessageFiles,\n        setSelectedChat,\n        setChats,\n        setChatFiles\n      )\n    } else {\n      const updatedChat = await updateChat(currentChat.id, {\n        updated_at: new Date().toISOString()\n      })\n\n      setChats(prevChats => {\n        const updatedChats = prevChats.map(prevChat =>\n          prevChat.id === updatedChat.id ? updatedChat : prevChat\n        )\n\n        return updatedChats\n      })\n    }\n\n    await handleCreateMessages(\n      chatMessages,\n      currentChat,\n      profile!,\n      modelData!,\n      messageContent,\n      generatedText,\n      newMessageImages,\n      isRegeneration,\n      retrievedFileItems,\n      setChatMessages,\n      setChatFileItems,\n      setChatImages,\n      selectedAssistant\n    )\n\n    setIsGenerating(false)\n    setFirstTokenReceived(false)\n  } catch (error) {\n    setIsGenerating(false)\n    setFirstTokenReceived(false)\n    setUserInput(startingInput)\n  }\n}\n\nconst handleSendEdit = async (\n  editedContent: string,\n  sequenceNumber: number\n) => {\n  if (!selectedChat) return\n\n  await deleteMessagesIncludingAndAfter(\n    selectedChat.user_id,\n    selectedChat.id,\n    sequenceNumber\n  )\n\n  const filteredMessages = chatMessages.filter(\n    chatMessage => chatMessage.message.sequence_number < sequenceNumber\n  )\n\n  setChatMessages(filteredMessages)\n\n  handleSendMessage(editedContent, filteredMessages, false)\n}\n\nreturn {\n  chatInputRef,\n  handleNewChat,\n  handleSendMessage,\n  handleFocusChatInput,\n  handleStopMessage,\n  handleSendEdit\n}\n}\n"
        }
    ]
}