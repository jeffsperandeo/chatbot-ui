{
    "sourceFile": "app/api/command/route.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1718133907897,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1718133907897,
            "name": "Commit-0",
            "content": "import { CHAT_SETTING_LIMITS } from \"@/lib/chat-setting-limits\"\nimport { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\nimport OpenAI from \"openai\"\n\nexport const runtime = \"edge\"\n\nexport async function POST(request: Request) {\n  const json = await request.json()\n  const { input } = json as {\n    input: string\n  }\n\n  try {\n    const profile = await getServerProfile()\n\n    checkApiKey(profile.openai_api_key, \"OpenAI\")\n\n    const openai = new OpenAI({\n      apiKey: profile.openai_api_key || \"\",\n      organization: profile.openai_organization_id\n    })\n\n    const response = await openai.chat.completions.create({\n      model: \"gpt-4-1106-preview\",\n      messages: [\n        {\n          role: \"system\",\n          content: \"Respond to the user.\"\n        },\n        {\n          role: \"user\",\n          content: input\n        }\n      ],\n      temperature: 0,\n      max_tokens:\n        CHAT_SETTING_LIMITS[\"gpt-4-turbo-preview\"].MAX_TOKEN_OUTPUT_LENGTH\n      //   response_format: { type: \"json_object\" }\n      //   stream: true\n    })\n\n    const content = response.choices[0].message.content\n\n    return new Response(JSON.stringify({ content }), {\n      status: 200\n    })\n  } catch (error: any) {\n    const errorMessage = error.error?.message || \"An unexpected error occurred\"\n    const errorCode = error.status || 500\n    return new Response(JSON.stringify({ message: errorMessage }), {\n      status: errorCode\n    })\n  }\n}\n"
        }
    ]
}