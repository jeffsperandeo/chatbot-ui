{
    "sourceFile": "app/api/chat/openai/route.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 19,
            "patches": [
                {
                    "date": 1717938728436,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1717938744967,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717938753194,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n+import { ChatCompletionCreateParamsBase } from \"openai\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717939026178,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/resources/chat/completions.mjs\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n@@ -54,5 +54,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n+}\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717940137406,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/resources/chat/completions.mjs\"\n+import { ChatCompletionCreateParamsBase } from \"openai\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717940155808,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717940196320,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n+import { ChatCompletionCreateParamsBase } from \"openai\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717940203301,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717941333976,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,10 +2,11 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n+import { ChatCompletionCreateParamsBase } from 'openai';\n \n+\n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n   const json = await request.json()\n"
                },
                {
                    "date": 1717948459036,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,59 @@\n+import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n+import { ChatSettings } from \"@/types\"\n+import { OpenAIStream, StreamingTextResponse } from \"ai\"\n+import { ServerRuntime } from \"next\"\n+import OpenAI from \"openai\"\n+import { ChatCompletionCreateParamsBase } from 'openai';\n+\n+\n+export const runtime: ServerRuntime = \"edge\"\n+\n+export async function POST(request: Request) {\n+  const json = await request.json()\n+  const { chatSettings, messages } = json as {\n+    chatSettings: ChatSettings\n+    messages: any[]\n+  }\n+\n+  try {\n+    const profile = await getServerProfile()\n+\n+    checkApiKey(profile.openai_api_key, \"OpenAI\")\n+\n+    const openai = new OpenAI({\n+      apiKey: profile.openai_api_key || \"\",\n+      organization: profile.openai_organization_id\n+    })\n+\n+    const response = await openai.chat.completions.create({\n+      model: chatSettings.model as ChatCompletionCreateParamsBase[\"model\"],\n+      messages: messages as ChatCompletionCreateParamsBase[\"messages\"],\n+      temperature: chatSettings.temperature,\n+      max_tokens:\n+        chatSettings.model === \"gpt-4-vision-preview\" ||\n+        chatSettings.model === \"gpt-4o\"\n+          ? 4096\n+          : null, // TODO: Fix\n+      stream: true\n+    })\n+\n+    const stream = OpenAIStream(response)\n+\n+    return new StreamingTextResponse(stream)\n+  } catch (error: any) {\n+    let errorMessage = error.message || \"An unexpected error occurred\"\n+    const errorCode = error.status || 500\n+\n+    if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n+      errorMessage =\n+        \"OpenAI API Key not found. Please set it in your profile settings.\"\n+    } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n+      errorMessage =\n+        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n+    }\n+\n+    return new Response(JSON.stringify({ message: errorMessage }), {\n+      status: errorCode\n+    })\n+  }\n+}\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717948469442,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from 'openai';\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\";\n \n \n export const runtime: ServerRuntime = \"edge\"\n \n@@ -55,64 +55,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n-import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n-import { ChatSettings } from \"@/types\"\n-import { OpenAIStream, StreamingTextResponse } from \"ai\"\n-import { ServerRuntime } from \"next\"\n-import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from 'openai';\n-\n-\n-export const runtime: ServerRuntime = \"edge\"\n-\n-export async function POST(request: Request) {\n-  const json = await request.json()\n-  const { chatSettings, messages } = json as {\n-    chatSettings: ChatSettings\n-    messages: any[]\n-  }\n-\n-  try {\n-    const profile = await getServerProfile()\n-\n-    checkApiKey(profile.openai_api_key, \"OpenAI\")\n-\n-    const openai = new OpenAI({\n-      apiKey: profile.openai_api_key || \"\",\n-      organization: profile.openai_organization_id\n-    })\n-\n-    const response = await openai.chat.completions.create({\n-      model: chatSettings.model as ChatCompletionCreateParamsBase[\"model\"],\n-      messages: messages as ChatCompletionCreateParamsBase[\"messages\"],\n-      temperature: chatSettings.temperature,\n-      max_tokens:\n-        chatSettings.model === \"gpt-4-vision-preview\" ||\n-        chatSettings.model === \"gpt-4o\"\n-          ? 4096\n-          : null, // TODO: Fix\n-      stream: true\n-    })\n-\n-    const stream = OpenAIStream(response)\n-\n-    return new StreamingTextResponse(stream)\n-  } catch (error: any) {\n-    let errorMessage = error.message || \"An unexpected error occurred\"\n-    const errorCode = error.status || 500\n-\n-    if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n-      errorMessage =\n-        \"OpenAI API Key not found. Please set it in your profile settings.\"\n-    } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n-      errorMessage =\n-        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n-    }\n-\n-    return new Response(JSON.stringify({ message: errorMessage }), {\n-      status: errorCode\n-    })\n-  }\n }\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717948479671,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\";\n+import { ChatCompletionCreateParamsBase } from 'openai';\n \n \n export const runtime: ServerRuntime = \"edge\"\n \n"
                },
                {
                    "date": 1718018429443,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,11 +2,10 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from 'openai';\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n \n-\n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n   const json = await request.json()\n@@ -55,5 +54,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n\\ No newline at end of file\n+}\n"
                },
                {
                    "date": 1718018448527,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n+import { ChatCompletionCreateParamsBase } from \"openai\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1718018525423,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/resources/chat/completions.mjs\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n@@ -54,5 +54,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n+}\n\\ No newline at end of file\n"
                },
                {
                    "date": 1718019335194,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,10 +2,11 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/resources/chat/completions.mjs\"\n+import ChatCompletionCreateParamsBase from \"openai\";\n \n+\n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n   const json = await request.json()\n@@ -54,5 +55,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n\\ No newline at end of file\n+}\n"
                },
                {
                    "date": 1718019440195,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,59 +1,57 @@\n-import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n-import { ChatSettings } from \"@/types\"\n-import { OpenAIStream, StreamingTextResponse } from \"ai\"\n-import { ServerRuntime } from \"next\"\n-import OpenAI from \"openai\"\n-import ChatCompletionCreateParamsBase from \"openai\";\n+import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\";\n+import { ChatSettings } from \"@/types\";\n+import { OpenAIStream, StreamingTextResponse } from \"ai\";\n+import { ServerRuntime } from \"next\";\n+import OpenAI from \"openai\";\n \n+export const runtime: ServerRuntime = \"edge\";\n \n-export const runtime: ServerRuntime = \"edge\"\n-\n export async function POST(request: Request) {\n-  const json = await request.json()\n+  const json = await request.json();\n   const { chatSettings, messages } = json as {\n-    chatSettings: ChatSettings\n-    messages: any[]\n-  }\n+    chatSettings: ChatSettings;\n+    messages: any[];\n+  };\n \n   try {\n-    const profile = await getServerProfile()\n+    const profile = await getServerProfile();\n \n-    checkApiKey(profile.openai_api_key, \"OpenAI\")\n+    checkApiKey(profile.openai_api_key, \"OpenAI\");\n \n     const openai = new OpenAI({\n       apiKey: profile.openai_api_key || \"\",\n-      organization: profile.openai_organization_id\n-    })\n+      organization: profile.openai_organization_id,\n+    });\n \n-    const response = await openai.chat.completions.create({\n-      model: chatSettings.model as ChatCompletionCreateParamsBase[\"model\"],\n-      messages: messages as ChatCompletionCreateParamsBase[\"messages\"],\n+    const response = await openai.completions.create({\n+      model: chatSettings.model,\n+      messages: messages,\n       temperature: chatSettings.temperature,\n       max_tokens:\n         chatSettings.model === \"gpt-4-vision-preview\" ||\n         chatSettings.model === \"gpt-4o\"\n           ? 4096\n-          : null, // TODO: Fix\n-      stream: true\n-    })\n+          : undefined, // Adjusted to use undefined instead of null\n+      stream: true,\n+    });\n \n-    const stream = OpenAIStream(response)\n+    const stream = OpenAIStream(response);\n \n-    return new StreamingTextResponse(stream)\n+    return new StreamingTextResponse(stream);\n   } catch (error: any) {\n-    let errorMessage = error.message || \"An unexpected error occurred\"\n-    const errorCode = error.status || 500\n+    let errorMessage = error.message || \"An unexpected error occurred\";\n+    const errorCode = error.status || 500;\n \n     if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n       errorMessage =\n-        \"OpenAI API Key not found. Please set it in your profile settings.\"\n+        \"OpenAI API Key not found. Please set it in your profile settings.\";\n     } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n       errorMessage =\n-        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n+        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\";\n     }\n \n     return new Response(JSON.stringify({ message: errorMessage }), {\n-      status: errorCode\n-    })\n+      status: errorCode,\n+    });\n   }\n }\n"
                },
                {
                    "date": 1718019508172,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n       apiKey: profile.openai_api_key || \"\",\n       organization: profile.openai_organization_id,\n     });\n \n-    const response = await openai.completions.create({\n+    const response = await openai.chat.create({\n       model: chatSettings.model,\n       messages: messages,\n       temperature: chatSettings.temperature,\n       max_tokens:\n"
                },
                {
                    "date": 1718019595659,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,21 +22,24 @@\n       apiKey: profile.openai_api_key || \"\",\n       organization: profile.openai_organization_id,\n     });\n \n-    const response = await openai.chat.create({\n+    const stream = await openai.chat.completions.stream({\n       model: chatSettings.model,\n       messages: messages,\n       temperature: chatSettings.temperature,\n       max_tokens:\n         chatSettings.model === \"gpt-4-vision-preview\" ||\n         chatSettings.model === \"gpt-4o\"\n           ? 4096\n-          : undefined, // Adjusted to use undefined instead of null\n+          : undefined,\n       stream: true,\n     });\n \n-    const stream = OpenAIStream(response);\n+    for await (const chunk of stream) {\n+      // Process the stream chunks here\n+      console.log(chunk.choices[0]?.delta?.content || '');\n+    }\n \n     return new StreamingTextResponse(stream);\n   } catch (error: any) {\n     let errorMessage = error.message || \"An unexpected error occurred\";\n"
                },
                {
                    "date": 1718019657575,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,36 +22,28 @@\n       apiKey: profile.openai_api_key || \"\",\n       organization: profile.openai_organization_id,\n     });\n \n-    const stream = await openai.chat.completions.stream({\n+    const response = await openai.chat.completions.create({\n       model: chatSettings.model,\n       messages: messages,\n       temperature: chatSettings.temperature,\n-      max_tokens:\n-        chatSettings.model === \"gpt-4-vision-preview\" ||\n-        chatSettings.model === \"gpt-4o\"\n-          ? 4096\n-          : undefined,\n+      max_tokens: chatSettings.model === \"gpt-4-vision-preview\" || chatSettings.model === \"gpt-4o\" ? 4096 : undefined,\n       stream: true,\n     });\n \n-    for await (const chunk of stream) {\n-      // Process the stream chunks here\n-      console.log(chunk.choices[0]?.delta?.content || '');\n-    }\n+    // Convert the response into a stream\n+    const stream = OpenAIStream(response);\n \n     return new StreamingTextResponse(stream);\n   } catch (error: any) {\n     let errorMessage = error.message || \"An unexpected error occurred\";\n     const errorCode = error.status || 500;\n \n     if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n-      errorMessage =\n-        \"OpenAI API Key not found. Please set it in your profile settings.\";\n+      errorMessage = \"OpenAI API Key not found. Please set it in your profile settings.\";\n     } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n-      errorMessage =\n-        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\";\n+      errorMessage = \"OpenAI API Key is incorrect. Please fix it in your profile settings.\";\n     }\n \n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode,\n"
                }
            ],
            "date": 1717938728436,
            "name": "Commit-0",
            "content": "import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\nimport { ChatSettings } from \"@/types\"\nimport { OpenAIStream, StreamingTextResponse } from \"ai\"\nimport { ServerRuntime } from \"next\"\nimport OpenAI from \"openai\"\nimport { ChatCompletionCreateParamsBase } from \"openai\"\n\nexport const runtime: ServerRuntime = \"edge\"\n\nexport async function POST(request: Request) {\n  const json = await request.json()\n  const { chatSettings, messages } = json as {\n    chatSettings: ChatSettings\n    messages: any[]\n  }\n\n  try {\n    const profile = await getServerProfile()\n\n    checkApiKey(profile.openai_api_key, \"OpenAI\")\n\n    const openai = new OpenAI({\n      apiKey: profile.openai_api_key || \"\",\n      organization: profile.openai_organization_id\n    })\n\n    const response = await openai.chat.completions.create({\n      model: chatSettings.model as ChatCompletionCreateParamsBase[\"model\"],\n      messages: messages as ChatCompletionCreateParamsBase[\"messages\"],\n      temperature: chatSettings.temperature,\n      max_tokens:\n        chatSettings.model === \"gpt-4-vision-preview\" ||\n        chatSettings.model === \"gpt-4o\"\n          ? 4096\n          : null, // TODO: Fix\n      stream: true\n    })\n\n    const stream = OpenAIStream(response)\n\n    return new StreamingTextResponse(stream)\n  } catch (error: any) {\n    let errorMessage = error.message || \"An unexpected error occurred\"\n    const errorCode = error.status || 500\n\n    if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n      errorMessage =\n        \"OpenAI API Key not found. Please set it in your profile settings.\"\n    } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n      errorMessage =\n        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n    }\n\n    return new Response(JSON.stringify({ message: errorMessage }), {\n      status: errorCode\n    })\n  }\n}\n"
        }
    ]
}