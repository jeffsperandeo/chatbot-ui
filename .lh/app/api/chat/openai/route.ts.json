{
    "sourceFile": "app/api/chat/openai/route.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 11,
            "patches": [
                {
                    "date": 1717938728436,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1717938744967,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717938753194,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n+import { ChatCompletionCreateParamsBase } from \"openai\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717939026178,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/resources/chat/completions.mjs\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n@@ -54,5 +54,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n+}\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717940137406,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/resources/chat/completions.mjs\"\n+import { ChatCompletionCreateParamsBase } from \"openai\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717940155808,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717940196320,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n+import { ChatCompletionCreateParamsBase } from \"openai\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717940203301,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717941333976,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,10 +2,11 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n+import { ChatCompletionCreateParamsBase } from 'openai';\n \n+\n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n   const json = await request.json()\n"
                },
                {
                    "date": 1717948459036,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,59 @@\n+import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n+import { ChatSettings } from \"@/types\"\n+import { OpenAIStream, StreamingTextResponse } from \"ai\"\n+import { ServerRuntime } from \"next\"\n+import OpenAI from \"openai\"\n+import { ChatCompletionCreateParamsBase } from 'openai';\n+\n+\n+export const runtime: ServerRuntime = \"edge\"\n+\n+export async function POST(request: Request) {\n+  const json = await request.json()\n+  const { chatSettings, messages } = json as {\n+    chatSettings: ChatSettings\n+    messages: any[]\n+  }\n+\n+  try {\n+    const profile = await getServerProfile()\n+\n+    checkApiKey(profile.openai_api_key, \"OpenAI\")\n+\n+    const openai = new OpenAI({\n+      apiKey: profile.openai_api_key || \"\",\n+      organization: profile.openai_organization_id\n+    })\n+\n+    const response = await openai.chat.completions.create({\n+      model: chatSettings.model as ChatCompletionCreateParamsBase[\"model\"],\n+      messages: messages as ChatCompletionCreateParamsBase[\"messages\"],\n+      temperature: chatSettings.temperature,\n+      max_tokens:\n+        chatSettings.model === \"gpt-4-vision-preview\" ||\n+        chatSettings.model === \"gpt-4o\"\n+          ? 4096\n+          : null, // TODO: Fix\n+      stream: true\n+    })\n+\n+    const stream = OpenAIStream(response)\n+\n+    return new StreamingTextResponse(stream)\n+  } catch (error: any) {\n+    let errorMessage = error.message || \"An unexpected error occurred\"\n+    const errorCode = error.status || 500\n+\n+    if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n+      errorMessage =\n+        \"OpenAI API Key not found. Please set it in your profile settings.\"\n+    } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n+      errorMessage =\n+        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n+    }\n+\n+    return new Response(JSON.stringify({ message: errorMessage }), {\n+      status: errorCode\n+    })\n+  }\n+}\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717948469442,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from 'openai';\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\";\n \n \n export const runtime: ServerRuntime = \"edge\"\n \n@@ -55,64 +55,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n-import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n-import { ChatSettings } from \"@/types\"\n-import { OpenAIStream, StreamingTextResponse } from \"ai\"\n-import { ServerRuntime } from \"next\"\n-import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from 'openai';\n-\n-\n-export const runtime: ServerRuntime = \"edge\"\n-\n-export async function POST(request: Request) {\n-  const json = await request.json()\n-  const { chatSettings, messages } = json as {\n-    chatSettings: ChatSettings\n-    messages: any[]\n-  }\n-\n-  try {\n-    const profile = await getServerProfile()\n-\n-    checkApiKey(profile.openai_api_key, \"OpenAI\")\n-\n-    const openai = new OpenAI({\n-      apiKey: profile.openai_api_key || \"\",\n-      organization: profile.openai_organization_id\n-    })\n-\n-    const response = await openai.chat.completions.create({\n-      model: chatSettings.model as ChatCompletionCreateParamsBase[\"model\"],\n-      messages: messages as ChatCompletionCreateParamsBase[\"messages\"],\n-      temperature: chatSettings.temperature,\n-      max_tokens:\n-        chatSettings.model === \"gpt-4-vision-preview\" ||\n-        chatSettings.model === \"gpt-4o\"\n-          ? 4096\n-          : null, // TODO: Fix\n-      stream: true\n-    })\n-\n-    const stream = OpenAIStream(response)\n-\n-    return new StreamingTextResponse(stream)\n-  } catch (error: any) {\n-    let errorMessage = error.message || \"An unexpected error occurred\"\n-    const errorCode = error.status || 500\n-\n-    if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n-      errorMessage =\n-        \"OpenAI API Key not found. Please set it in your profile settings.\"\n-    } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n-      errorMessage =\n-        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n-    }\n-\n-    return new Response(JSON.stringify({ message: errorMessage }), {\n-      status: errorCode\n-    })\n-  }\n }\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717948479671,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\";\n+import { ChatCompletionCreateParamsBase } from 'openai';\n \n \n export const runtime: ServerRuntime = \"edge\"\n \n"
                }
            ],
            "date": 1717938728436,
            "name": "Commit-0",
            "content": "import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\nimport { ChatSettings } from \"@/types\"\nimport { OpenAIStream, StreamingTextResponse } from \"ai\"\nimport { ServerRuntime } from \"next\"\nimport OpenAI from \"openai\"\nimport { ChatCompletionCreateParamsBase } from \"openai\"\n\nexport const runtime: ServerRuntime = \"edge\"\n\nexport async function POST(request: Request) {\n  const json = await request.json()\n  const { chatSettings, messages } = json as {\n    chatSettings: ChatSettings\n    messages: any[]\n  }\n\n  try {\n    const profile = await getServerProfile()\n\n    checkApiKey(profile.openai_api_key, \"OpenAI\")\n\n    const openai = new OpenAI({\n      apiKey: profile.openai_api_key || \"\",\n      organization: profile.openai_organization_id\n    })\n\n    const response = await openai.chat.completions.create({\n      model: chatSettings.model as ChatCompletionCreateParamsBase[\"model\"],\n      messages: messages as ChatCompletionCreateParamsBase[\"messages\"],\n      temperature: chatSettings.temperature,\n      max_tokens:\n        chatSettings.model === \"gpt-4-vision-preview\" ||\n        chatSettings.model === \"gpt-4o\"\n          ? 4096\n          : null, // TODO: Fix\n      stream: true\n    })\n\n    const stream = OpenAIStream(response)\n\n    return new StreamingTextResponse(stream)\n  } catch (error: any) {\n    let errorMessage = error.message || \"An unexpected error occurred\"\n    const errorCode = error.status || 500\n\n    if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n      errorMessage =\n        \"OpenAI API Key not found. Please set it in your profile settings.\"\n    } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n      errorMessage =\n        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n    }\n\n    return new Response(JSON.stringify({ message: errorMessage }), {\n      status: errorCode\n    })\n  }\n}\n"
        }
    ]
}