{
    "sourceFile": "app/api/chat/openai/route.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 25,
            "patches": [
                {
                    "date": 1717938728436,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1717938744967,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717938753194,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n+import { ChatCompletionCreateParamsBase } from \"openai\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717939026178,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/resources/chat/completions.mjs\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n@@ -54,5 +54,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n+}\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717940137406,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/resources/chat/completions.mjs\"\n+import { ChatCompletionCreateParamsBase } from \"openai\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717940155808,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717940196320,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n+import { ChatCompletionCreateParamsBase } from \"openai\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717940203301,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1717941333976,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,10 +2,11 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n+import { ChatCompletionCreateParamsBase } from 'openai';\n \n+\n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n   const json = await request.json()\n"
                },
                {
                    "date": 1717948459036,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,59 @@\n+import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n+import { ChatSettings } from \"@/types\"\n+import { OpenAIStream, StreamingTextResponse } from \"ai\"\n+import { ServerRuntime } from \"next\"\n+import OpenAI from \"openai\"\n+import { ChatCompletionCreateParamsBase } from 'openai';\n+\n+\n+export const runtime: ServerRuntime = \"edge\"\n+\n+export async function POST(request: Request) {\n+  const json = await request.json()\n+  const { chatSettings, messages } = json as {\n+    chatSettings: ChatSettings\n+    messages: any[]\n+  }\n+\n+  try {\n+    const profile = await getServerProfile()\n+\n+    checkApiKey(profile.openai_api_key, \"OpenAI\")\n+\n+    const openai = new OpenAI({\n+      apiKey: profile.openai_api_key || \"\",\n+      organization: profile.openai_organization_id\n+    })\n+\n+    const response = await openai.chat.completions.create({\n+      model: chatSettings.model as ChatCompletionCreateParamsBase[\"model\"],\n+      messages: messages as ChatCompletionCreateParamsBase[\"messages\"],\n+      temperature: chatSettings.temperature,\n+      max_tokens:\n+        chatSettings.model === \"gpt-4-vision-preview\" ||\n+        chatSettings.model === \"gpt-4o\"\n+          ? 4096\n+          : null, // TODO: Fix\n+      stream: true\n+    })\n+\n+    const stream = OpenAIStream(response)\n+\n+    return new StreamingTextResponse(stream)\n+  } catch (error: any) {\n+    let errorMessage = error.message || \"An unexpected error occurred\"\n+    const errorCode = error.status || 500\n+\n+    if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n+      errorMessage =\n+        \"OpenAI API Key not found. Please set it in your profile settings.\"\n+    } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n+      errorMessage =\n+        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n+    }\n+\n+    return new Response(JSON.stringify({ message: errorMessage }), {\n+      status: errorCode\n+    })\n+  }\n+}\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717948469442,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from 'openai';\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\";\n \n \n export const runtime: ServerRuntime = \"edge\"\n \n@@ -55,64 +55,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n-import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n-import { ChatSettings } from \"@/types\"\n-import { OpenAIStream, StreamingTextResponse } from \"ai\"\n-import { ServerRuntime } from \"next\"\n-import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from 'openai';\n-\n-\n-export const runtime: ServerRuntime = \"edge\"\n-\n-export async function POST(request: Request) {\n-  const json = await request.json()\n-  const { chatSettings, messages } = json as {\n-    chatSettings: ChatSettings\n-    messages: any[]\n-  }\n-\n-  try {\n-    const profile = await getServerProfile()\n-\n-    checkApiKey(profile.openai_api_key, \"OpenAI\")\n-\n-    const openai = new OpenAI({\n-      apiKey: profile.openai_api_key || \"\",\n-      organization: profile.openai_organization_id\n-    })\n-\n-    const response = await openai.chat.completions.create({\n-      model: chatSettings.model as ChatCompletionCreateParamsBase[\"model\"],\n-      messages: messages as ChatCompletionCreateParamsBase[\"messages\"],\n-      temperature: chatSettings.temperature,\n-      max_tokens:\n-        chatSettings.model === \"gpt-4-vision-preview\" ||\n-        chatSettings.model === \"gpt-4o\"\n-          ? 4096\n-          : null, // TODO: Fix\n-      stream: true\n-    })\n-\n-    const stream = OpenAIStream(response)\n-\n-    return new StreamingTextResponse(stream)\n-  } catch (error: any) {\n-    let errorMessage = error.message || \"An unexpected error occurred\"\n-    const errorCode = error.status || 500\n-\n-    if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n-      errorMessage =\n-        \"OpenAI API Key not found. Please set it in your profile settings.\"\n-    } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n-      errorMessage =\n-        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n-    }\n-\n-    return new Response(JSON.stringify({ message: errorMessage }), {\n-      status: errorCode\n-    })\n-  }\n }\n\\ No newline at end of file\n"
                },
                {
                    "date": 1717948479671,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\";\n+import { ChatCompletionCreateParamsBase } from 'openai';\n \n \n export const runtime: ServerRuntime = \"edge\"\n \n"
                },
                {
                    "date": 1718018429443,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,11 +2,10 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from 'openai';\n+import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n \n-\n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n   const json = await request.json()\n@@ -55,5 +54,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n\\ No newline at end of file\n+}\n"
                },
                {
                    "date": 1718018448527,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/dist/base\"\n+import { ChatCompletionCreateParamsBase } from \"openai\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n"
                },
                {
                    "date": 1718018525423,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,9 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai\"\n+import { ChatCompletionCreateParamsBase } from \"openai/resources/chat/completions.mjs\"\n \n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n@@ -54,5 +54,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n+}\n\\ No newline at end of file\n"
                },
                {
                    "date": 1718019335194,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,10 +2,11 @@\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n-import { ChatCompletionCreateParamsBase } from \"openai/resources/chat/completions.mjs\"\n+import ChatCompletionCreateParamsBase from \"openai\";\n \n+\n export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n   const json = await request.json()\n@@ -54,5 +55,5 @@\n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode\n     })\n   }\n-}\n\\ No newline at end of file\n+}\n"
                },
                {
                    "date": 1718019440195,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,59 +1,57 @@\n-import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n-import { ChatSettings } from \"@/types\"\n-import { OpenAIStream, StreamingTextResponse } from \"ai\"\n-import { ServerRuntime } from \"next\"\n-import OpenAI from \"openai\"\n-import ChatCompletionCreateParamsBase from \"openai\";\n+import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\";\n+import { ChatSettings } from \"@/types\";\n+import { OpenAIStream, StreamingTextResponse } from \"ai\";\n+import { ServerRuntime } from \"next\";\n+import OpenAI from \"openai\";\n \n+export const runtime: ServerRuntime = \"edge\";\n \n-export const runtime: ServerRuntime = \"edge\"\n-\n export async function POST(request: Request) {\n-  const json = await request.json()\n+  const json = await request.json();\n   const { chatSettings, messages } = json as {\n-    chatSettings: ChatSettings\n-    messages: any[]\n-  }\n+    chatSettings: ChatSettings;\n+    messages: any[];\n+  };\n \n   try {\n-    const profile = await getServerProfile()\n+    const profile = await getServerProfile();\n \n-    checkApiKey(profile.openai_api_key, \"OpenAI\")\n+    checkApiKey(profile.openai_api_key, \"OpenAI\");\n \n     const openai = new OpenAI({\n       apiKey: profile.openai_api_key || \"\",\n-      organization: profile.openai_organization_id\n-    })\n+      organization: profile.openai_organization_id,\n+    });\n \n-    const response = await openai.chat.completions.create({\n-      model: chatSettings.model as ChatCompletionCreateParamsBase[\"model\"],\n-      messages: messages as ChatCompletionCreateParamsBase[\"messages\"],\n+    const response = await openai.completions.create({\n+      model: chatSettings.model,\n+      messages: messages,\n       temperature: chatSettings.temperature,\n       max_tokens:\n         chatSettings.model === \"gpt-4-vision-preview\" ||\n         chatSettings.model === \"gpt-4o\"\n           ? 4096\n-          : null, // TODO: Fix\n-      stream: true\n-    })\n+          : undefined, // Adjusted to use undefined instead of null\n+      stream: true,\n+    });\n \n-    const stream = OpenAIStream(response)\n+    const stream = OpenAIStream(response);\n \n-    return new StreamingTextResponse(stream)\n+    return new StreamingTextResponse(stream);\n   } catch (error: any) {\n-    let errorMessage = error.message || \"An unexpected error occurred\"\n-    const errorCode = error.status || 500\n+    let errorMessage = error.message || \"An unexpected error occurred\";\n+    const errorCode = error.status || 500;\n \n     if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n       errorMessage =\n-        \"OpenAI API Key not found. Please set it in your profile settings.\"\n+        \"OpenAI API Key not found. Please set it in your profile settings.\";\n     } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n       errorMessage =\n-        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n+        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\";\n     }\n \n     return new Response(JSON.stringify({ message: errorMessage }), {\n-      status: errorCode\n-    })\n+      status: errorCode,\n+    });\n   }\n }\n"
                },
                {
                    "date": 1718019508172,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n       apiKey: profile.openai_api_key || \"\",\n       organization: profile.openai_organization_id,\n     });\n \n-    const response = await openai.completions.create({\n+    const response = await openai.chat.create({\n       model: chatSettings.model,\n       messages: messages,\n       temperature: chatSettings.temperature,\n       max_tokens:\n"
                },
                {
                    "date": 1718019595659,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,21 +22,24 @@\n       apiKey: profile.openai_api_key || \"\",\n       organization: profile.openai_organization_id,\n     });\n \n-    const response = await openai.chat.create({\n+    const stream = await openai.chat.completions.stream({\n       model: chatSettings.model,\n       messages: messages,\n       temperature: chatSettings.temperature,\n       max_tokens:\n         chatSettings.model === \"gpt-4-vision-preview\" ||\n         chatSettings.model === \"gpt-4o\"\n           ? 4096\n-          : undefined, // Adjusted to use undefined instead of null\n+          : undefined,\n       stream: true,\n     });\n \n-    const stream = OpenAIStream(response);\n+    for await (const chunk of stream) {\n+      // Process the stream chunks here\n+      console.log(chunk.choices[0]?.delta?.content || '');\n+    }\n \n     return new StreamingTextResponse(stream);\n   } catch (error: any) {\n     let errorMessage = error.message || \"An unexpected error occurred\";\n"
                },
                {
                    "date": 1718019657575,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,36 +22,28 @@\n       apiKey: profile.openai_api_key || \"\",\n       organization: profile.openai_organization_id,\n     });\n \n-    const stream = await openai.chat.completions.stream({\n+    const response = await openai.chat.completions.create({\n       model: chatSettings.model,\n       messages: messages,\n       temperature: chatSettings.temperature,\n-      max_tokens:\n-        chatSettings.model === \"gpt-4-vision-preview\" ||\n-        chatSettings.model === \"gpt-4o\"\n-          ? 4096\n-          : undefined,\n+      max_tokens: chatSettings.model === \"gpt-4-vision-preview\" || chatSettings.model === \"gpt-4o\" ? 4096 : undefined,\n       stream: true,\n     });\n \n-    for await (const chunk of stream) {\n-      // Process the stream chunks here\n-      console.log(chunk.choices[0]?.delta?.content || '');\n-    }\n+    // Convert the response into a stream\n+    const stream = OpenAIStream(response);\n \n     return new StreamingTextResponse(stream);\n   } catch (error: any) {\n     let errorMessage = error.message || \"An unexpected error occurred\";\n     const errorCode = error.status || 500;\n \n     if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n-      errorMessage =\n-        \"OpenAI API Key not found. Please set it in your profile settings.\";\n+      errorMessage = \"OpenAI API Key not found. Please set it in your profile settings.\";\n     } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n-      errorMessage =\n-        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\";\n+      errorMessage = \"OpenAI API Key is incorrect. Please fix it in your profile settings.\";\n     }\n \n     return new Response(JSON.stringify({ message: errorMessage }), {\n       status: errorCode,\n"
                },
                {
                    "date": 1718039355720,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,52 +1,58 @@\n-import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\";\n-import { ChatSettings } from \"@/types\";\n-import { OpenAIStream, StreamingTextResponse } from \"ai\";\n-import { ServerRuntime } from \"next\";\n-import OpenAI from \"openai\";\n+import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n+import { ChatSettings } from \"@/types\"\n+import { OpenAIStream, StreamingTextResponse } from \"ai\"\n+import { ServerRuntime } from \"next\"\n+import OpenAI from \"openai\"\n \n-export const runtime: ServerRuntime = \"edge\";\n+export const runtime: ServerRuntime = \"edge\"\n \n export async function POST(request: Request) {\n-  const json = await request.json();\n+  const json = await request.json()\n   const { chatSettings, messages } = json as {\n-    chatSettings: ChatSettings;\n-    messages: any[];\n-  };\n+    chatSettings: ChatSettings\n+    messages: any[]\n+  }\n \n   try {\n-    const profile = await getServerProfile();\n+    const profile = await getServerProfile()\n \n-    checkApiKey(profile.openai_api_key, \"OpenAI\");\n+    checkApiKey(profile.openai_api_key, \"OpenAI\")\n \n     const openai = new OpenAI({\n       apiKey: profile.openai_api_key || \"\",\n-      organization: profile.openai_organization_id,\n-    });\n+      organization: profile.openai_organization_id\n+    })\n \n     const response = await openai.chat.completions.create({\n       model: chatSettings.model,\n       messages: messages,\n       temperature: chatSettings.temperature,\n-      max_tokens: chatSettings.model === \"gpt-4-vision-preview\" || chatSettings.model === \"gpt-4o\" ? 4096 : undefined,\n-      stream: true,\n-    });\n+      max_tokens:\n+        chatSettings.model === \"gpt-4-vision-preview\" ||\n+        chatSettings.model === \"gpt-4o\"\n+          ? 4096\n+          : undefined,\n+      stream: true\n+    })\n \n     // Convert the response into a stream\n-    const stream = OpenAIStream(response);\n+    const stream = OpenAIStream(response)\n \n-    return new StreamingTextResponse(stream);\n+    return new StreamingTextResponse(stream)\n   } catch (error: any) {\n-    let errorMessage = error.message || \"An unexpected error occurred\";\n-    const errorCode = error.status || 500;\n+    let errorMessage = error.message || \"An unexpected error occurred\"\n+    const errorCode = error.status || 500\n \n     if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n-      errorMessage = \"OpenAI API Key not found. Please set it in your profile settings.\";\n+      errorMessage =\n+        \"OpenAI API Key not found. Please set it in your profile settings.\"\n     } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n-      errorMessage = \"OpenAI API Key is incorrect. Please fix it in your profile settings.\";\n+      errorMessage =\n+        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n     }\n \n     return new Response(JSON.stringify({ message: errorMessage }), {\n-      status: errorCode,\n-    });\n+      status: errorCode\n+    })\n   }\n }\n"
                },
                {
                    "date": 1718042521164,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,6 @@\n-import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n+import { getServerProfile } from \"@/lib/server/server-chat-helpers\"\n+import { checkApiKey } from \"@/lib/server/api-key-helpers\"\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n"
                },
                {
                    "date": 1718042537144,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,5 @@\n-import { getServerProfile } from \"@/lib/server/server-chat-helpers\"\n-import { checkApiKey } from \"@/lib/server/api-key-helpers\"\n+import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n import OpenAI from \"openai\"\n"
                },
                {
                    "date": 1718042863476,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,58 +1,73 @@\n-import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n-import { ChatSettings } from \"@/types\"\n-import { OpenAIStream, StreamingTextResponse } from \"ai\"\n-import { ServerRuntime } from \"next\"\n-import OpenAI from \"openai\"\n+import { Database, Tables } from \"@/supabase/types\"\n+import { VALID_ENV_KEYS } from \"@/types/valid-keys\"\n+import { createServerClient } from \"@supabase/ssr\"\n+import { cookies } from \"next/headers\"\n \n-export const runtime: ServerRuntime = \"edge\"\n+export async function getServerProfile() {\n+  const cookieStore = cookies()\n+  const supabase = createServerClient<Database>(\n+    process.env.NEXT_PUBLIC_SUPABASE_URL!,\n+    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,\n+    {\n+      cookies: {\n+        get(name: string) {\n+          return cookieStore.get(name)?.value\n+        }\n+      }\n+    }\n+  )\n \n-export async function POST(request: Request) {\n-  const json = await request.json()\n-  const { chatSettings, messages } = json as {\n-    chatSettings: ChatSettings\n-    messages: any[]\n+  const user = (await supabase.auth.getUser()).data.user\n+  if (!user) {\n+    throw new Error(\"User not found\")\n   }\n \n-  try {\n-    const profile = await getServerProfile()\n+  const { data: profile } = await supabase\n+    .from(\"profiles\")\n+    .select(\"*\")\n+    .eq(\"user_id\", user.id)\n+    .single()\n \n-    checkApiKey(profile.openai_api_key, \"OpenAI\")\n+  if (!profile) {\n+    throw new Error(\"Profile not found\")\n+  }\n \n-    const openai = new OpenAI({\n-      apiKey: profile.openai_api_key || \"\",\n-      organization: profile.openai_organization_id\n-    })\n+  const profileWithKeys = addApiKeysToProfile(profile)\n \n-    const response = await openai.chat.completions.create({\n-      model: chatSettings.model,\n-      messages: messages,\n-      temperature: chatSettings.temperature,\n-      max_tokens:\n-        chatSettings.model === \"gpt-4-vision-preview\" ||\n-        chatSettings.model === \"gpt-4o\"\n-          ? 4096\n-          : undefined,\n-      stream: true\n-    })\n+  return profileWithKeys\n+}\n \n-    // Convert the response into a stream\n-    const stream = OpenAIStream(response)\n+function addApiKeysToProfile(profile: Tables<\"profiles\">) {\n+  const apiKeys = {\n+    [VALID_ENV_KEYS.OPENAI_API_KEY]: \"openai_api_key\",\n+    [VALID_ENV_KEYS.ANTHROPIC_API_KEY]: \"anthropic_api_key\",\n+    [VALID_ENV_KEYS.GOOGLE_GEMINI_API_KEY]: \"google_gemini_api_key\",\n+    [VALID_ENV_KEYS.MISTRAL_API_KEY]: \"mistral_api_key\",\n+    [VALID_ENV_KEYS.GROQ_API_KEY]: \"groq_api_key\",\n+    [VALID_ENV_KEYS.PERPLEXITY_API_KEY]: \"perplexity_api_key\",\n+    [VALID_ENV_KEYS.AZURE_OPENAI_API_KEY]: \"azure_openai_api_key\",\n+    [VALID_ENV_KEYS.OPENROUTER_API_KEY]: \"openrouter_api_key\",\n \n-    return new StreamingTextResponse(stream)\n-  } catch (error: any) {\n-    let errorMessage = error.message || \"An unexpected error occurred\"\n-    const errorCode = error.status || 500\n+    [VALID_ENV_KEYS.OPENAI_ORGANIZATION_ID]: \"openai_organization_id\",\n \n-    if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n-      errorMessage =\n-        \"OpenAI API Key not found. Please set it in your profile settings.\"\n-    } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n-      errorMessage =\n-        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n+    [VALID_ENV_KEYS.AZURE_OPENAI_ENDPOINT]: \"azure_openai_endpoint\",\n+    [VALID_ENV_KEYS.AZURE_GPT_35_TURBO_NAME]: \"azure_openai_35_turbo_id\",\n+    [VALID_ENV_KEYS.AZURE_GPT_45_VISION_NAME]: \"azure_openai_45_vision_id\",\n+    [VALID_ENV_KEYS.AZURE_GPT_45_TURBO_NAME]: \"azure_openai_45_turbo_id\",\n+    [VALID_ENV_KEYS.AZURE_EMBEDDINGS_NAME]: \"azure_openai_embeddings_id\"\n+  }\n+\n+  for (const [envKey, profileKey] of Object.entries(apiKeys)) {\n+    if (process.env[envKey]) {\n+      ;(profile as any)[profileKey] = process.env[envKey]\n     }\n+  }\n \n-    return new Response(JSON.stringify({ message: errorMessage }), {\n-      status: errorCode\n-    })\n+  return profile\n+}\n+\n+export function checkApiKey(apiKey: string | null, keyName: string) {\n+  if (apiKey === null || apiKey === \"\") {\n+    throw new Error(`${keyName} API Key not found`)\n   }\n }\n"
                },
                {
                    "date": 1718042880239,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,73 +1,58 @@\n-import { Database, Tables } from \"@/supabase/types\"\n-import { VALID_ENV_KEYS } from \"@/types/valid-keys\"\n-import { createServerClient } from \"@supabase/ssr\"\n-import { cookies } from \"next/headers\"\n+import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n+import { ChatSettings } from \"@/types\"\n+import { OpenAIStream, StreamingTextResponse } from \"ai\"\n+import { ServerRuntime } from \"next\"\n+import OpenAI from \"openai\"\n \n-export async function getServerProfile() {\n-  const cookieStore = cookies()\n-  const supabase = createServerClient<Database>(\n-    process.env.NEXT_PUBLIC_SUPABASE_URL!,\n-    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,\n-    {\n-      cookies: {\n-        get(name: string) {\n-          return cookieStore.get(name)?.value\n-        }\n-      }\n-    }\n-  )\n+export const runtime: ServerRuntime = \"edge\"\n \n-  const user = (await supabase.auth.getUser()).data.user\n-  if (!user) {\n-    throw new Error(\"User not found\")\n+export async function POST(request: Request) {\n+  const json = await request.json()\n+  const { chatSettings, messages } = json as {\n+    chatSettings: ChatSettings\n+    messages: any[]\n   }\n \n-  const { data: profile } = await supabase\n-    .from(\"profiles\")\n-    .select(\"*\")\n-    .eq(\"user_id\", user.id)\n-    .single()\n+  try {\n+    const profile = await getServerProfile()\n \n-  if (!profile) {\n-    throw new Error(\"Profile not found\")\n-  }\n+    checkApiKey(profile.openai_api_key, \"OpenAI\")\n \n-  const profileWithKeys = addApiKeysToProfile(profile)\n+    const openai = new OpenAI({\n+      apiKey: profile.openai_api_key || \"\",\n+      organization: profile.openai_organization_id\n+    })\n \n-  return profileWithKeys\n-}\n+    const response = await openai.chat.completions.create({\n+      model: chatSettings.model,\n+      messages: messages,\n+      temperature: chatSettings.temperature,\n+      max_tokens:\n+        chatSettings.model === \"gpt-4-vision-preview\" ||\n+        chatSettings.model === \"gpt-4o\"\n+          ? 4096\n+          : undefined,\n+      stream: true\n+    })\n \n-function addApiKeysToProfile(profile: Tables<\"profiles\">) {\n-  const apiKeys = {\n-    [VALID_ENV_KEYS.OPENAI_API_KEY]: \"openai_api_key\",\n-    [VALID_ENV_KEYS.ANTHROPIC_API_KEY]: \"anthropic_api_key\",\n-    [VALID_ENV_KEYS.GOOGLE_GEMINI_API_KEY]: \"google_gemini_api_key\",\n-    [VALID_ENV_KEYS.MISTRAL_API_KEY]: \"mistral_api_key\",\n-    [VALID_ENV_KEYS.GROQ_API_KEY]: \"groq_api_key\",\n-    [VALID_ENV_KEYS.PERPLEXITY_API_KEY]: \"perplexity_api_key\",\n-    [VALID_ENV_KEYS.AZURE_OPENAI_API_KEY]: \"azure_openai_api_key\",\n-    [VALID_ENV_KEYS.OPENROUTER_API_KEY]: \"openrouter_api_key\",\n+    // Convert the response into a stream\n+    const stream = OpenAIStream(response)\n \n-    [VALID_ENV_KEYS.OPENAI_ORGANIZATION_ID]: \"openai_organization_id\",\n+    return new StreamingTextResponse(stream)\n+  } catch (error: any) {\n+    let errorMessage = error.message || \"An unexpected error occurred\"\n+    const errorCode = error.status || 500\n \n-    [VALID_ENV_KEYS.AZURE_OPENAI_ENDPOINT]: \"azure_openai_endpoint\",\n-    [VALID_ENV_KEYS.AZURE_GPT_35_TURBO_NAME]: \"azure_openai_35_turbo_id\",\n-    [VALID_ENV_KEYS.AZURE_GPT_45_VISION_NAME]: \"azure_openai_45_vision_id\",\n-    [VALID_ENV_KEYS.AZURE_GPT_45_TURBO_NAME]: \"azure_openai_45_turbo_id\",\n-    [VALID_ENV_KEYS.AZURE_EMBEDDINGS_NAME]: \"azure_openai_embeddings_id\"\n-  }\n-\n-  for (const [envKey, profileKey] of Object.entries(apiKeys)) {\n-    if (process.env[envKey]) {\n-      ;(profile as any)[profileKey] = process.env[envKey]\n+    if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n+      errorMessage =\n+        \"OpenAI API Key not found. Please set it in your profile settings.\"\n+    } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n+      errorMessage =\n+        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n     }\n-  }\n \n-  return profile\n-}\n-\n-export function checkApiKey(apiKey: string | null, keyName: string) {\n-  if (apiKey === null || apiKey === \"\") {\n-    throw new Error(`${keyName} API Key not found`)\n+    return new Response(JSON.stringify({ message: errorMessage }), {\n+      status: errorCode\n+    })\n   }\n }\n"
                },
                {
                    "date": 1718289273061,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,4 +1,5 @@\n+// app/api/chat/openai/route.ts\n import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\n import { ChatSettings } from \"@/types\"\n import { OpenAIStream, StreamingTextResponse } from \"ai\"\n import { ServerRuntime } from \"next\"\n"
                }
            ],
            "date": 1717938728436,
            "name": "Commit-0",
            "content": "import { checkApiKey, getServerProfile } from \"@/lib/server/server-chat-helpers\"\nimport { ChatSettings } from \"@/types\"\nimport { OpenAIStream, StreamingTextResponse } from \"ai\"\nimport { ServerRuntime } from \"next\"\nimport OpenAI from \"openai\"\nimport { ChatCompletionCreateParamsBase } from \"openai\"\n\nexport const runtime: ServerRuntime = \"edge\"\n\nexport async function POST(request: Request) {\n  const json = await request.json()\n  const { chatSettings, messages } = json as {\n    chatSettings: ChatSettings\n    messages: any[]\n  }\n\n  try {\n    const profile = await getServerProfile()\n\n    checkApiKey(profile.openai_api_key, \"OpenAI\")\n\n    const openai = new OpenAI({\n      apiKey: profile.openai_api_key || \"\",\n      organization: profile.openai_organization_id\n    })\n\n    const response = await openai.chat.completions.create({\n      model: chatSettings.model as ChatCompletionCreateParamsBase[\"model\"],\n      messages: messages as ChatCompletionCreateParamsBase[\"messages\"],\n      temperature: chatSettings.temperature,\n      max_tokens:\n        chatSettings.model === \"gpt-4-vision-preview\" ||\n        chatSettings.model === \"gpt-4o\"\n          ? 4096\n          : null, // TODO: Fix\n      stream: true\n    })\n\n    const stream = OpenAIStream(response)\n\n    return new StreamingTextResponse(stream)\n  } catch (error: any) {\n    let errorMessage = error.message || \"An unexpected error occurred\"\n    const errorCode = error.status || 500\n\n    if (errorMessage.toLowerCase().includes(\"api key not found\")) {\n      errorMessage =\n        \"OpenAI API Key not found. Please set it in your profile settings.\"\n    } else if (errorMessage.toLowerCase().includes(\"incorrect api key\")) {\n      errorMessage =\n        \"OpenAI API Key is incorrect. Please fix it in your profile settings.\"\n    }\n\n    return new Response(JSON.stringify({ message: errorMessage }), {\n      status: errorCode\n    })\n  }\n}\n"
        }
    ]
}